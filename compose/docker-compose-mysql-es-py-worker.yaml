services:
  elasticsearch:
    container_name: temporal-elasticsearch
    environment:
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=512mb
      - cluster.routing.allocation.disk.watermark.high=256mb
      - cluster.routing.allocation.disk.watermark.flood_stage=128mb
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
      - xpack.security.enabled=false
    image: elasticsearch:9.0.2
    networks:
      - temporal-network
    # ports:
    #   - 9200:9200
    volumes:
      - /var/lib/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=1s || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
  mysql:
    container_name: temporal-mysql
    environment:
      - MYSQL_ROOT_PASSWORD=root
    image: mysql:9.3.0-oracle
    command:
      # Connection settings for high QPS
      - --max-connections=20000
      - --max-user-connections=19500
      - --back-log=5000
      - --max-connect-errors=10000000
      - --thread-cache-size=500

      # InnoDB main performance settings
      - --innodb-buffer-pool-size=6G
      - --innodb-log-buffer-size=256M
      - --innodb-redo-log-capacity=512M
      - --innodb-flush-log-at-trx-commit=2
      - --innodb-flush-method=O_DIRECT
      - --innodb-io-capacity=1000
      - --innodb-io-capacity-max=2000
      - --innodb-read-io-threads=8
      - --innodb-write-io-threads=8

      # Cache and tables
      - --table-open-cache=10000
      - --table-definition-cache=4000
      - --max-allowed-packet=512M
      - --tmp-table-size=512M
      - --max-heap-table-size=512M

      # Optimized timeouts
      - --interactive-timeout=28800
      - --wait-timeout=28800
      - --net-read-timeout=60
      - --net-write-timeout=60

      # Buffers for operations
      - --sort-buffer-size=2M
      - --join-buffer-size=2M
      - --read-buffer-size=1M
      - --read-rnd-buffer-size=2M

      # Performance optimization
      - --skip-name-resolve
      - --skip-external-locking

      # Binary logs disabled for maximum QPS
      - --skip-log-bin

      # Settings for high QPS
      - --innodb-stats-on-metadata=OFF
    networks:
      - temporal-network
    # ports:
    #   - 3306:3306
    tmpfs:
      - /var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-proot"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    # deploy:
    #   resources:
    #     limits:
    #       memory: 16G
    #       cpus: '8.0'
    #     reservations:
    #       memory: 12G
    #       cpus: '4.0'
    # ulimits:
    #   nofile:
    #     soft: 65536
    #     hard: 65536
    #   nproc: 65536
    #   memlock:
    #     soft: -1
    #     hard: -1

  # Init jobs for setting up infrastructure
  check-elasticsearch:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - temporal-network
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      - ES_SCHEME=http
      - ES_USER=
      - ES_PWD=
    entrypoint: >
      sh -c "until curl --silent --fail --user \"$$ES_USER:$$ES_PWD\" $$ES_SCHEME://$$ES_HOST:$$ES_PORT 2>&1 > /dev/null; do
        echo waiting for elasticsearch to start;
        sleep 5;
      done;"
    restart: "no"

  create-default-store:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      mysql:
        condition: service_healthy
    networks:
      - temporal-network
    environment:
      - SQL_PLUGIN=mysql8
      - SQL_HOST=mysql
      - SQL_PORT=3306
      - SQL_USER=root
      - SQL_PASSWORD=root
      - SQL_DATABASE=temporal
    entrypoint: >
      sh -c "until nc -z mysql 3306; do
        echo waiting for mysql to accept connections on port 3306;
        sleep 3;
      done &&
      echo mysql is ready, creating database... &&
      for i in 1 2 3 4 5; do
        echo attempt $$i to create database;
        temporal-sql-tool create-database && break || sleep 5;
      done"
    restart: "no"

  setup-default-store:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      create-default-store:
        condition: service_completed_successfully
    networks:
      - temporal-network
    environment:
      - SQL_PLUGIN=mysql8
      - SQL_HOST=mysql
      - SQL_PORT=3306
      - SQL_USER=root
      - SQL_PASSWORD=root
      - SQL_DATABASE=temporal
    entrypoint: >
      sh -c "for i in 1 2 3 4 5; do
        echo attempt $$i to setup schema;
        temporal-sql-tool setup-schema -v 0.0 && break || sleep 5;
      done"
    restart: "no"

  update-default-store:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      setup-default-store:
        condition: service_completed_successfully
    networks:
      - temporal-network
    environment:
      - SQL_PLUGIN=mysql8
      - SQL_HOST=mysql
      - SQL_PORT=3306
      - SQL_USER=root
      - SQL_PASSWORD=root
      - SQL_DATABASE=temporal
    entrypoint: >
      sh -c "for i in 1 2 3 4 5; do
        echo attempt $$i to update schema;
        temporal-sql-tool update-schema --schema-dir /etc/temporal/schema/mysql/v8/temporal/versioned && break || sleep 5;
      done"
    restart: "no"

  setup-visibility-store:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      check-elasticsearch:
        condition: service_completed_successfully
    networks:
      - temporal-network
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      - ES_SCHEME=http
      - ES_USER=
      - ES_PWD=
      - ES_VERSION=v7
      - ES_VISIBILITY_INDEX=temporal_visibility_v1_dev
    entrypoint: >
      sh -c "for i in 1 2 3 4 5; do
        echo attempt $$i to setup visibility store;
        curl -X PUT --fail --user \"$$ES_USER:$$ES_PWD\" $$ES_SCHEME://$$ES_HOST:$$ES_PORT/_template/temporal_visibility_v1_template -H \"Content-Type: application/json\" --data-binary \"@schema/elasticsearch/visibility/index_template_$$ES_VERSION.json\" 2>&1 &&
        (curl --head --fail --user \"$$ES_USER:$$ES_PWD\" $$ES_SCHEME://$$ES_HOST:$$ES_PORT/$$ES_VISIBILITY_INDEX 2>&1 ||
        curl -X PUT --fail --user \"$$ES_USER:$$ES_PWD\" $$ES_SCHEME://$$ES_HOST:$$ES_PORT/$$ES_VISIBILITY_INDEX 2>&1) && break || sleep 5;
      done"
    restart: "no"

  temporalio-history:
    deploy:
      mode: replicated
      replicas: 5
    depends_on:
      update-default-store:
        condition: service_completed_successfully
      setup-visibility-store:
        condition: service_completed_successfully
    environment:
      - SERVICES=history
      - TEMPORAL_STORE_PASSWORD=root
      - TEMPORAL_VISIBILITY_STORE_PASSWORD=
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - USE_INTERNAL_FRONTEND=1

    image: temporalio/server:1.27.2
    networks:
      - temporal-network
    volumes:
      - ./dynamicconfig/dynamic_config_sql.yaml:/etc/temporal/dynamic_config/dynamic_config.yaml
      - ./config_sql.yaml:/etc/temporal/config/config_template.yaml
    entrypoint: ["sh", "-c", "export POD_IP=$$(hostname -i | awk '{print $$1}') && exec /etc/temporal/entrypoint.sh"]
  temporalio-matching:
    deploy:
      mode: replicated
      replicas: 5
    depends_on:
      update-default-store:
        condition: service_completed_successfully
      setup-visibility-store:
        condition: service_completed_successfully
    environment:
      - SERVICES=matching
      - TEMPORAL_STORE_PASSWORD=root
      - TEMPORAL_VISIBILITY_STORE_PASSWORD=
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - USE_INTERNAL_FRONTEND=1
    image: temporalio/server:1.27.2
    networks:
      - temporal-network
    volumes:
      - ./dynamicconfig/dynamic_config_sql.yaml:/etc/temporal/dynamic_config/dynamic_config.yaml
      - ./config_sql.yaml:/etc/temporal/config/config_template.yaml
    entrypoint: ["sh", "-c", "export POD_IP=$$(hostname -i | awk '{print $$1}') && exec /etc/temporal/entrypoint.sh"]
  temporalio-worker:
    deploy:
      mode: replicated
      replicas: 5
    depends_on:
      update-default-store:
        condition: service_completed_successfully
      setup-visibility-store:
        condition: service_completed_successfully
    environment:
      - SERVICES=worker
      - TEMPORAL_STORE_PASSWORD=root
      - TEMPORAL_VISIBILITY_STORE_PASSWORD=
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - USE_INTERNAL_FRONTEND=1

    image: temporalio/server:1.27.2
    networks:
      - temporal-network
    volumes:
      - ./dynamicconfig/dynamic_config_sql.yaml:/etc/temporal/dynamic_config/dynamic_config.yaml
      - ./config_sql.yaml:/etc/temporal/config/config_template.yaml
    entrypoint: ["sh", "-c", "export POD_IP=$$(hostname -i | awk '{print $$1}') && exec /etc/temporal/entrypoint.sh"]
  temporalio-frontend:
    deploy:
      mode: replicated
      replicas: 5
    depends_on:
      update-default-store:
        condition: service_completed_successfully
      setup-visibility-store:
        condition: service_completed_successfully
    environment:
      - SERVICES=frontend
      - TEMPORAL_STORE_PASSWORD=root
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - TEMPORAL_VISIBILITY_STORE_PASSWORD=
      - USE_INTERNAL_FRONTEND=1

    image: temporalio/server:1.27.2
    networks:
      - temporal-network
    volumes:
      - ./dynamicconfig/dynamic_config_sql.yaml:/etc/temporal/dynamic_config/dynamic_config.yaml
      - ./config_sql.yaml:/etc/temporal/config/config_template.yaml
    entrypoint: ["sh", "-c", "export POD_IP=$$(hostname -i | awk '{print $$1}') && exec /etc/temporal/entrypoint.sh"]
  temporalio-internal-frontend:
    deploy:
      mode: replicated
      replicas: 5
    depends_on:
      update-default-store:
        condition: service_completed_successfully
      setup-visibility-store:
        condition: service_completed_successfully
    environment:
      - SERVICES=internal-frontend
      - TEMPORAL_STORE_PASSWORD=root
      - TEMPORAL_VISIBILITY_STORE_PASSWORD=
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - USE_INTERNAL_FRONTEND=1

    image: temporalio/server:1.27.2
    networks:
      - temporal-network
    volumes:
      - ./dynamicconfig/dynamic_config_sql.yaml:/etc/temporal/dynamic_config/dynamic_config.yaml
      - ./config_sql.yaml:/etc/temporal/config/config_template.yaml
    entrypoint: ["sh", "-c", "export POD_IP=$$(hostname -i | awk '{print $$1}') && exec /etc/temporal/entrypoint.sh"]

  create-default-namespace:
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    depends_on:
      - temporalio-internal-frontend
    networks:
      - temporal-network
    environment:
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7236
    entrypoint: >
      sh -c "until nc -z temporalio-internal-frontend 7236; do
        echo waiting for temporal internal-frontend to start on port 7236;
        sleep 5;
      done &&
      echo internal-frontend is ready, creating namespace... &&
      for i in 1 2 3 4 5; do
        echo attempt $$i to create namespace;
        temporal operator namespace describe -n default && break ||
        temporal operator namespace create -n default --retention 3d && break ||
        sleep 10;
      done"
    restart: "no"

  temporal-admin-tools:
    container_name: temporal-admin-tools
    depends_on:
      - temporalio-internal-frontend
    environment:
      - TEMPORAL_ADDRESS=temporalio-internal-frontend:7233
      - TEMPORAL_CLI_ADDRESS=temporalio-internal-frontend:7233
    image: temporalio/admin-tools:1.27.2-tctl-1.18.2-cli-1.3.0
    networks:
      - temporal-network
    stdin_open: true
    tty: true


  temporal-ui:
    container_name: temporal-ui
    depends_on:
      - temporalio-frontend
    environment:
      - TEMPORAL_ADDRESS=temporalio-frontend:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:v2.37.4
    networks:
      - temporal-network
    ports:
      - 8085:8080



  test-worker:
    build:
      context: ../
      args:
        PROJECT_NAME: "test-worker"
    depends_on:
      create-default-namespace:
        condition: service_completed_successfully
    restart: always
    environment:
      DEFAULT_TEMPORAL_URL: "temporalio-frontend:7233"
      DEFAULT_TEMPORAL_NAMESPACE: "default"
      TEMPORAL_WORKER_NAMESPACE: "default"
      TEMPORAL_WORKER_TASK_QUEUE: "benchmark"
      TEMPORAL_WORKER_TARGET_CPU: "0.9"
      TEMPORAL_WORKER_TARGET_RAM: "0.8"
      TEMPORAL_WORKER_WORKFLOWS_MIN_SLOTS: "10"
      TEMPORAL_WORKER_WORKFLOWS_MAX_SLOTS: "20"
      TEMPORAL_WORKER_ACTIVITIES_MIN_SLOTS: "50"
      TEMPORAL_WORKER_ACTIVITIES_MAX_SLOTS: "500"
      TEMPORAL_WORKER_LOCAL_ACTIVITIES_MIN_SLOTS: "50"
      TEMPORAL_WORKER_LOCAL_ACTIVITIES_MAX_SLOTS: "500"
      TEMPORAL_WORKER_MAX_CONCURRENT_WORKFLOW_TASK_POLLS: "100"
      TEMPORAL_WORKER_MAX_CONCURRENT_ACTIVITY_TASK_POLLS: "100"
      TEMPORAL_WORKER_NONSTICKY_TO_STICKY_POLL_RATIO: "0.5"
    networks:
      - temporal-network
    deploy:
      mode: replicated
      replicas: 10

  test-sheduler:
    build:
      context: ../
      args:
        PROJECT_NAME: "test-sheduler"
    depends_on:
      create-default-namespace:
        condition: service_completed_successfully
    restart: always
    environment:
      DEFAULT_TEMPORAL_URL: "temporalio-frontend:7233"
      DEFAULT_TEMPORAL_NAMESPACE: "default"
      SCHEDULER_TASK_QUEUE: "benchmark"
      SCHEDULER_NAMESPACE: "default"
      SCHEDULER_CONCURRENCY: "100"
      # SCHEDULER_TOTAL_WORKFLOWS: "100"
      SCHEDULER_MESSAGE: "Test scheduler"
      SCHEDULER_INFINITE_MODE: "true"
      SCHEDULER_REPORT_INTERVAL: "10"
      SCHEDULER_MAX_RUNTIME: "0"

    networks:
      - temporal-network
    deploy:
      mode: replicated
      replicas: 3




  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: temporal-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - temporal-network
    depends_on:
      - temporalio-frontend
      - temporalio-history
      - temporalio-matching
      - temporalio-worker

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.6.1
    container_name: temporal-node-exporter
    command:
      - '--path.rootfs=/host'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    networks:
      - temporal-network

  # MySQL Exporter for MySQL metrics
  mysqld-exporter:
    image: prom/mysqld-exporter:v0.17.2
    container_name: temporal-mysqld-exporter
    volumes:
      - ./my.cnf:/.my.cnf:ro
    ports:
      - "9104:9104"
    networks:
      - temporal-network
    depends_on:
      mysql:
        condition: service_healthy
    restart: always

  # Elasticsearch Exporter for Elasticsearch metrics
  elasticsearch-exporter:
    image: quay.io/prometheuscommunity/elasticsearch-exporter:v1.9.0
    container_name: temporal-elasticsearch-exporter
    command:
      - '--log.format=logfmt'
      - '--log.level=info'
      - '--es.uri=http://elasticsearch:9200'
      - '--es.all'
      - '--es.indices'
      - '--es.indices_settings'
      - '--es.indices_mappings'
      - '--es.shards'
      - '--collector.snapshots'
      - '--es.timeout=30s'
      - '--web.listen-address=:9108'
      - '--web.telemetry-path=/metrics'
    ports:
      - "9108:9108"
    networks:
      - temporal-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:9108/metrics || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Grafana for visualization
  grafana:
    image: grafana/grafana:10.1.0
    container_name: temporal-grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/:/etc/grafana/provisioning/
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "3001:3000"
    networks:
      - temporal-network
    depends_on:
      - prometheus

volumes:
  prometheus_data:
  grafana_data:
  mysql_data:
  mysql_logs:

networks:
  temporal-network:
    driver: bridge
    name: temporal-network
